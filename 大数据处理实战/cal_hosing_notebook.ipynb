{"nbformat_minor": 2, "cells": [{"execution_count": 7, "cell_type": "code", "source": "from pyspark.sql import *\nfrom pyspark.sql.types import *", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 15567.331787109375, "end_time": 1600691174666.126}}, "collapsed": false}}, {"execution_count": 9, "cell_type": "code", "source": "rdd = sc.textFile('/sptest/cal_housing.data')", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 1063.77490234375, "end_time": 1600691176381.142}}, "collapsed": true}}, {"execution_count": 10, "cell_type": "code", "source": "rdd.take(2)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "[u'-122.230000,37.880000,41.000000,880.000000,129.000000,322.000000,126.000000,8.325200,452600.000000', u'-122.220000,37.860000,21.000000,7099.000000,1106.000000,2401.000000,1138.000000,8.301400,358500.000000']"}], "metadata": {"cell_status": {"execute_time": {"duration": 1071.955078125, "end_time": 1600691229061.353}}, "collapsed": false}}, {"execution_count": 11, "cell_type": "code", "source": "rdd2 = rdd.map(lambda line: line.split(\",\"))\nrdd2.take(2)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "[[u'-122.230000', u'37.880000', u'41.000000', u'880.000000', u'129.000000', u'322.000000', u'126.000000', u'8.325200', u'452600.000000'], [u'-122.220000', u'37.860000', u'21.000000', u'7099.000000', u'1106.000000', u'2401.000000', u'1138.000000', u'8.301400', u'358500.000000']]"}], "metadata": {"cell_status": {"execute_time": {"duration": 6012.299072265625, "end_time": 1600691239794.385}}, "collapsed": false}}, {"execution_count": 30, "cell_type": "code", "source": "from pyspark.sql import Row\ndf = rdd2.map(lambda line: Row(longitude=line[0],\n                               latitude=line[1], \n                               housingMedianAge=line[2], \n                               totalRooms=line[3], \n                               totalBedRooms=line[4], \n                               population=line[5], \n                               households=line[6], \n                               medianIncome=line[7], \n                               medianHouseValue=line[8])).toDF()", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 2540.7919921875, "end_time": 1600692583720.35}}, "collapsed": false}}, {"execution_count": 13, "cell_type": "code", "source": "df.show()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+-----------+----------------+---------+-----------+----------------+------------+-----------+-------------+-----------+\n| households|housingMedianAge| latitude|  longitude|medianHouseValue|medianIncome| population|totalBedRooms| totalRooms|\n+-----------+----------------+---------+-----------+----------------+------------+-----------+-------------+-----------+\n| 126.000000|       41.000000|37.880000|-122.230000|   452600.000000|    8.325200| 322.000000|   129.000000| 880.000000|\n|1138.000000|       21.000000|37.860000|-122.220000|   358500.000000|    8.301400|2401.000000|  1106.000000|7099.000000|\n| 177.000000|       52.000000|37.850000|-122.240000|   352100.000000|    7.257400| 496.000000|   190.000000|1467.000000|\n| 219.000000|       52.000000|37.850000|-122.250000|   341300.000000|    5.643100| 558.000000|   235.000000|1274.000000|\n| 259.000000|       52.000000|37.850000|-122.250000|   342200.000000|    3.846200| 565.000000|   280.000000|1627.000000|\n| 193.000000|       52.000000|37.850000|-122.250000|   269700.000000|    4.036800| 413.000000|   213.000000| 919.000000|\n| 514.000000|       52.000000|37.840000|-122.250000|   299200.000000|    3.659100|1094.000000|   489.000000|2535.000000|\n| 647.000000|       52.000000|37.840000|-122.250000|   241400.000000|    3.120000|1157.000000|   687.000000|3104.000000|\n| 595.000000|       42.000000|37.840000|-122.260000|   226700.000000|    2.080400|1206.000000|   665.000000|2555.000000|\n| 714.000000|       52.000000|37.840000|-122.250000|   261100.000000|    3.691200|1551.000000|   707.000000|3549.000000|\n| 402.000000|       52.000000|37.850000|-122.260000|   281500.000000|    3.203100| 910.000000|   434.000000|2202.000000|\n| 734.000000|       52.000000|37.850000|-122.260000|   241800.000000|    3.270500|1504.000000|   752.000000|3503.000000|\n| 468.000000|       52.000000|37.850000|-122.260000|   213500.000000|    3.075000|1098.000000|   474.000000|2491.000000|\n| 174.000000|       52.000000|37.840000|-122.260000|   191300.000000|    2.673600| 345.000000|   191.000000| 696.000000|\n| 620.000000|       52.000000|37.850000|-122.260000|   159200.000000|    1.916700|1212.000000|   626.000000|2643.000000|\n| 264.000000|       50.000000|37.850000|-122.260000|   140000.000000|    2.125000| 697.000000|   283.000000|1120.000000|\n| 331.000000|       52.000000|37.850000|-122.270000|   152500.000000|    2.775000| 793.000000|   347.000000|1966.000000|\n| 303.000000|       52.000000|37.850000|-122.270000|   155500.000000|    2.120200| 648.000000|   293.000000|1228.000000|\n| 419.000000|       50.000000|37.840000|-122.260000|   158700.000000|    1.991100| 990.000000|   455.000000|2239.000000|\n| 275.000000|       52.000000|37.840000|-122.270000|   162900.000000|    2.603300| 690.000000|   298.000000|1503.000000|\n+-----------+----------------+---------+-----------+----------------+------------+-----------+-------------+-----------+\nonly showing top 20 rows"}], "metadata": {"cell_status": {"execute_time": {"duration": 139.56787109375, "end_time": 1600691249292.706}}, "collapsed": false}}, {"execution_count": 17, "cell_type": "code", "source": "def convertColumn(df, names, newType):\n    for name in names:\n        df = df.withColumn(name, df[name].cast(newType))\n    return df", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 16197.667236328125, "end_time": 1600691485286.743}}, "collapsed": false}}, {"execution_count": 31, "cell_type": "code", "source": "from pyspark.sql.functions import col\ncolumns = ['households', 'housingMedianAge', 'latitude', 'longitude', 'medianHouseValue', 'medianIncome', 'population', 'totalBedRooms', 'totalRooms']\ndf = convertColumn(df, columns, FloatType())\ndf = df.withColumn(\"medianHouseValue\", col(\"medianHouseValue\")/100000)\n\ndf = df.withColumn(\"roomsPerHousehold\", col(\"totalRooms\")/col(\"households\"))\ndf = df.withColumn(\"populationPerHousehold\", col(\"population\")/col(\"households\"))\ndf = df.withColumn(\"bedroomsPerRoom\", col(\"totalBedRooms\")/col(\"totalRooms\"))\n\n\ndf = df.select(\"medianHouseValue\",\n             \"totalBedRooms\",\n             \"population\",\n             \"households\",\n             \"medianIncome\",\n             \"roomsPerHousehold\",\n             \"populationPerHousehold\",\n             \"bedroomsPerRoom\")\ndf.show(5)\n\n# df.groupBy(\"housingMedianAge\").count().sort(\"housingMedianAge\",ascending=False).show()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+----------------+-------------+----------+----------+------------+------------------+----------------------+-------------------+\n|medianHouseValue|totalBedRooms|population|households|medianIncome| roomsPerHousehold|populationPerHousehold|    bedroomsPerRoom|\n+----------------+-------------+----------+----------+------------+------------------+----------------------+-------------------+\n|           4.526|        129.0|     322.0|     126.0|      8.3252| 6.984126984126984|    2.5555555555555554|0.14659090909090908|\n|           3.585|       1106.0|    2401.0|    1138.0|      8.3014| 6.238137082601054|     2.109841827768014|0.15579659106916466|\n|           3.521|        190.0|     496.0|     177.0|      7.2574| 8.288135593220339|    2.8022598870056497|0.12951601908657123|\n|           3.413|        235.0|     558.0|     219.0|      5.6431|5.8173515981735155|     2.547945205479452|0.18445839874411302|\n|           3.422|        280.0|     565.0|     259.0|      3.8462| 6.281853281853282|    2.1814671814671813| 0.1720958819913952|\n+----------------+-------------+----------+----------+------------+------------------+----------------------+-------------------+\nonly showing top 5 rows"}], "metadata": {"cell_status": {"execute_time": {"duration": 1538.76806640625, "end_time": 1600692644016.071}}, "collapsed": false}}, {"execution_count": 32, "cell_type": "code", "source": "df.take(2)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "[Row(medianHouseValue=4.526, totalBedRooms=129.0, population=322.0, households=126.0, medianIncome=8.325200080871582, roomsPerHousehold=6.984126984126984, populationPerHousehold=2.5555555555555554, bedroomsPerRoom=0.14659090909090908), Row(medianHouseValue=3.585, totalBedRooms=1106.0, population=2401.0, households=1138.0, medianIncome=8.301400184631348, roomsPerHousehold=6.238137082601054, populationPerHousehold=2.109841827768014, bedroomsPerRoom=0.15579659106916466)]"}], "metadata": {"cell_status": {"execute_time": {"duration": 1569.466064453125, "end_time": 1600692695137.422}}, "collapsed": false}}, {"execution_count": 34, "cell_type": "code", "source": "# \u628a DataFrame \u8f6c\u6362\u6210 RDD\uff0c\u7136\u540e\u7528 map() \u51fd\u6570\u628a\u6bcf\u4e2a\u5bf9\u8c61\u5206\u6210\u4e24\u90e8\u5206\uff1a\u623f\u4ef7\u548c\u4e00\u4e2a\u5305\u542b\u5176\u4f59\u5c5e\u6027\u7684\u5217\u8868\uff0c\u7136\u540e.\u5728\u8f6c\u6362\u56de DataFrame\u3002\nfrom pyspark.ml.linalg import DenseVector\n\ninput_data = df.rdd.map(lambda x: (x[0], DenseVector(x[1:])))\ndf_ = spark.createDataFrame(input_data, [\"label\", \"features\"])", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 1642.10498046875, "end_time": 1600692767765.452}}, "collapsed": false}}, {"execution_count": 35, "cell_type": "code", "source": "df_.show(5)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+-----+--------------------+\n|label|            features|\n+-----+--------------------+\n|4.526|[129.0,322.0,126....|\n|3.585|[1106.0,2401.0,11...|\n|3.521|[190.0,496.0,177....|\n|3.413|[235.0,558.0,219....|\n|3.422|[280.0,565.0,259....|\n+-----+--------------------+\nonly showing top 5 rows"}], "metadata": {"cell_status": {"execute_time": {"duration": 905.730224609375, "end_time": 1600692818923.233}}, "collapsed": false}}, {"execution_count": 36, "cell_type": "code", "source": "df.take(2)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "[Row(medianHouseValue=4.526, totalBedRooms=129.0, population=322.0, households=126.0, medianIncome=8.325200080871582, roomsPerHousehold=6.984126984126984, populationPerHousehold=2.5555555555555554, bedroomsPerRoom=0.14659090909090908), Row(medianHouseValue=3.585, totalBedRooms=1106.0, population=2401.0, households=1138.0, medianIncome=8.301400184631348, roomsPerHousehold=6.238137082601054, populationPerHousehold=2.109841827768014, bedroomsPerRoom=0.15579659106916466)]"}], "metadata": {"cell_status": {"execute_time": {"duration": 7434.8681640625, "end_time": 1600692840785.776}}, "collapsed": false}}, {"execution_count": 37, "cell_type": "code", "source": "from pyspark.ml.feature import StandardScaler\n\nstandardScaler = StandardScaler(inputCol=\"features\", outputCol=\"features_scaled\")\nscaler = standardScaler.fit(df_)\nscaled_df = scaler.transform(df_)", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 1473.9189453125, "end_time": 1600692856424.639}}, "collapsed": true}}, {"execution_count": 38, "cell_type": "code", "source": "scaled_df.show(2)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+-----+--------------------+--------------------+\n|label|            features|     features_scaled|\n+-----+--------------------+--------------------+\n|4.526|[129.0,322.0,126....|[0.30623297630686...|\n|3.585|[1106.0,2401.0,11...|[2.62553233949917...|\n+-----+--------------------+--------------------+\nonly showing top 2 rows"}], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "", "outputs": [], "metadata": {"collapsed": true}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "PySpark", "name": "pysparkkernel", "language": ""}, "language_info": {"mimetype": "text/x-python", "pygments_lexer": "python2", "name": "pyspark", "codemirror_mode": {"version": 2, "name": "python"}}}}